{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1\n",
    "import os\n",
    "from fastf1 import plotting\n",
    "from fastf1.core import Laps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from __future__ import annotations\n",
    "from typing import List, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = './fastf1_cache'\n",
    "if not os.path.exists(CACHE_DIR):\n",
    "    os.makedirs(CACHE_DIR)\n",
    "    print(f\"Diretório de cache '{CACHE_DIR}' criado\")\n",
    "\n",
    "fastf1.Cache.clear_cache(CACHE_DIR) \n",
    "print(f\"Cache do FastF1 em '{CACHE_DIR}' limpo\")\n",
    "\n",
    "fastf1.Cache.enable_cache(CACHE_DIR)\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c6ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_main_dataset(year=2024, event='British Grand Prix', CACHE_DIR='./fastf1_cache', driver_filter=None, years_filter=None):\n",
    "    fastf1.Cache.enable_cache(CACHE_DIR)\n",
    "\n",
    "    try:\n",
    "        session = fastf1.get_session(year, event, 'R')\n",
    "        print(f\"Carregando sessão: {event} {year} - Corrida (R)\")\n",
    "        session.load(telemetry=True, weather=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar sessão: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    full_data = []\n",
    "\n",
    "    # Processar dados meteorológicos\n",
    "    weather_data = session.weather_data\n",
    "    if not weather_data.empty:\n",
    "        weather_data['Time'] = weather_data['Time'].dt.round('s')\n",
    "        weather_data_agg = weather_data.resample('1min', on='Time').mean().reset_index()\n",
    "    else:\n",
    "        weather_data_agg = pd.DataFrame()\n",
    "\n",
    "    for driver in session.drivers:\n",
    "        if driver_filter and driver != driver_filter:\n",
    "            continue\n",
    "\n",
    "        laps = session.laps.pick_driver(driver).pick_quicklaps()\n",
    "        if laps.empty:\n",
    "            continue\n",
    "\n",
    "        laps = laps.sort_values(by='LapNumber').reset_index(drop=True)\n",
    "        laps['stint_id'] = laps['Stint']\n",
    "        laps['s_lap'] = laps.groupby('stint_id').cumcount() + 1\n",
    "        laps['s_total'] = laps.groupby('stint_id')['LapNumber'].transform('count')\n",
    "        laps['s_pct'] = laps['s_lap'] / laps['s_total']\n",
    "        laps['best_s_lap'] = laps.groupby('stint_id')['LapTime'].transform('min').dt.total_seconds()\n",
    "        laps['delta_best'] = laps['LapTime'].dt.total_seconds() - laps['best_s_lap']\n",
    "        laps['delta_var'] = laps['delta_best'].diff().fillna(0)\n",
    "\n",
    "        # Estimativa de combustível\n",
    "        fuel_cons = 1.8\n",
    "        full_tank = 110\n",
    "        laps['fuel_kg'] = full_tank - (laps['LapNumber'] * fuel_cons)\n",
    "        laps['fuel_kg'] = laps['fuel_kg'].apply(lambda x: max(0, x))\n",
    "\n",
    "        laps['race_id'] = f\"{year}_{event.replace(' ', '_')}\"\n",
    "        laps['year'] = year\n",
    "        laps['race'] = event\n",
    "        laps['sc_active'] = laps['TrackStatus'].apply(lambda x: 1 if x in [2,3,4,5,6] else 0)\n",
    "\n",
    "        # Clima\n",
    "        if not weather_data_agg.empty and 'LapStartTime' in laps.columns:\n",
    "            try:\n",
    "                laps['LapStartTime_rounded'] = laps['LapStartTime'].dt.round('s')\n",
    "                laps = pd.merge_asof(\n",
    "                    laps.sort_values('LapStartTime_rounded'),\n",
    "                    weather_data_agg.sort_values('Time'),\n",
    "                    left_on='LapStartTime_rounded',\n",
    "                    right_on='Time',\n",
    "                    direction='nearest'\n",
    "                )\n",
    "                cols_to_drop = [col for col in ['LapStartTime_rounded', 'Time', 'Time_y'] if col in laps.columns]\n",
    "                laps = laps.drop(columns=cols_to_drop)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"⚠️ Erro ao mesclar clima para {driver}: {e}\")\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'race_id': laps['race_id'],\n",
    "            'year': laps['year'],\n",
    "            'race': laps['race'],\n",
    "            'drv': laps['Driver'],\n",
    "            'team': laps['Team'],\n",
    "            'lap': laps['LapNumber'],\n",
    "            's_lap': laps['s_lap'],\n",
    "            's_pct': laps['s_pct'],\n",
    "            'tyre': laps['Compound'],\n",
    "            'lap_time': laps['LapTime'].dt.total_seconds(),\n",
    "            'delta_best': laps['delta_best'],\n",
    "            'delta_var': laps['delta_var'],\n",
    "            'fuel_kg': laps['fuel_kg'],\n",
    "            'sc_active': laps['sc_active'],\n",
    "            'stint_id': laps['stint_id'],\n",
    "            'fresh_tyre': laps['FreshTyre'],\n",
    "            'speed_i1': laps['SpeedI1'],\n",
    "            'speed_i2': laps['SpeedI2'],\n",
    "            'speed_fl': laps['SpeedFL'],\n",
    "            'speed_st': laps['SpeedST'],\n",
    "            'air_temp': laps['AirTemp'] if 'AirTemp' in laps.columns else np.nan,\n",
    "            'track_temp': laps['TrackTemp'] if 'TrackTemp' in laps.columns else np.nan,\n",
    "            'humidity': laps['Humidity'] if 'Humidity' in laps.columns else np.nan,\n",
    "            'best_s_lap': laps['best_s_lap'],\n",
    "        })\n",
    "\n",
    "        full_data.append(df)\n",
    "\n",
    "    if full_data:\n",
    "        final_df = pd.concat(full_data, ignore_index=True)\n",
    "        filename = f\"tyre_wear_dataset_{year}_{event.replace(' ', '_')}.csv\"\n",
    "        final_df.to_csv(filename, index=False)\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"Nenhum dado disponível para criar o dataset\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def generate_deltas_dataset(\n",
    "    *,\n",
    "    year: int,\n",
    "    event: str,\n",
    "    CACHE_DIR: str = CACHE_DIR,\n",
    "    driver_filter: Optional[str] = None,\n",
    "    years_filter: Optional[List[int]] = None,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    if years_filter and year not in years_filter:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    fastf1.Cache.enable_cache(CACHE_DIR)\n",
    "\n",
    "    try:\n",
    "        session = fastf1.get_session(year, event, \"R\")\n",
    "        session.load(telemetry=True)\n",
    "    except Exception as exc:\n",
    "        logger.error(\"Erro ao carregar telemetria %s %d: %s\", event, year, exc)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_delta: List[pd.DataFrame] = []\n",
    "\n",
    "    for drv_num in session.drivers:\n",
    "        drv_code = session.get_driver(drv_num)[\"Abbreviation\"]\n",
    "        if driver_filter and drv_code != driver_filter:\n",
    "            continue\n",
    "\n",
    "        laps = session.laps.pick_driver(drv_code).pick_quicklaps()\n",
    "        if laps.empty:\n",
    "            continue\n",
    "\n",
    "        base_df = pd.DataFrame(\n",
    "            {\n",
    "                \"race_id\": f\"{year}_{event.replace(' ', '_')}\",\n",
    "                \"drv\": drv_code,\n",
    "                \"lap\": laps[\"LapNumber\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            tel = laps.get_telemetry()\n",
    "            if tel.empty:\n",
    "                all_delta.append(base_df)\n",
    "                continue\n",
    "\n",
    "            tel.add_driver_ahead()\n",
    "            laps_time = laps[[\"LapNumber\", \"LapStartTime\", \"Time\"]].rename(\n",
    "                columns={\"Time\": \"LapEndTime\"}\n",
    "            )\n",
    "            tel = tel.sort_values(\"SessionTime\").reset_index(drop=True)\n",
    "            laps_time = laps_time.sort_values(\"LapStartTime\").reset_index(drop=True)\n",
    "\n",
    "            tel = pd.merge_asof(\n",
    "                tel,\n",
    "                laps_time,\n",
    "                left_on=\"SessionTime\",\n",
    "                right_on=\"LapStartTime\",\n",
    "                direction=\"backward\",\n",
    "            )\n",
    "            tel = tel[\n",
    "                (tel[\"SessionTime\"] >= tel[\"LapStartTime\"]) &\n",
    "                (tel[\"SessionTime\"] <= tel[\"LapEndTime\"])\n",
    "            ]\n",
    "            if tel.empty:\n",
    "                all_delta.append(base_df)\n",
    "                continue\n",
    "\n",
    "            dist = (\n",
    "                tel.groupby(\"LapNumber\")[\"DistanceToDriverAhead\"].mean().reset_index()\n",
    "            ).rename(columns={\"LapNumber\": \"lap\", \"DistanceToDriverAhead\": \"delta_s\"})\n",
    "\n",
    "            base_df = base_df.merge(dist, on=\"lap\", how=\"left\")\n",
    "        except Exception as exc:\n",
    "            logger.warning(\"Erro ao processar telemetria %s: %s\", drv_code, exc)\n",
    "            base_df[\"delta_s\"] = np.nan\n",
    "\n",
    "        all_delta.append(base_df)\n",
    "\n",
    "    return pd.concat(all_delta, ignore_index=True) if all_delta else pd.DataFrame()\n",
    "\n",
    "def merge_fastf1_dataframes(tyre_df: pd.DataFrame, delta_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if tyre_df.empty:\n",
    "        logger.warning(\"DataFrame de pneus vazio.\")\n",
    "        return pd.DataFrame()\n",
    "    if delta_df.empty:\n",
    "        logger.warning(\"DataFrame de delta vazio – retornando apenas pneus.\")\n",
    "        return tyre_df\n",
    "    return tyre_df.merge(delta_df, on=[\"race_id\", \"drv\", \"lap\"], how=\"left\")\n",
    "\n",
    "\n",
    "def add_analysis_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    FUEL_IMPACT = 0.03  # s/kg\n",
    "    df = df.copy()\n",
    "    df[\"delta_adjusted_fuel\"] = df[\"delta_best\"] - df[\"fuel_kg\"] * FUEL_IMPACT\n",
    "\n",
    "    avg_circuit_tyre = (\n",
    "        df.groupby([\"race_id\", \"tyre\"])[\"delta_best\"].mean().reset_index()\n",
    "    ).rename(columns={\"delta_best\": \"avg_delta_best_circuit_tyre\"})\n",
    "    df = df.merge(avg_circuit_tyre, on=[\"race_id\", \"tyre\"], how=\"left\")\n",
    "\n",
    "    avg_driver_tyre = (\n",
    "        df.groupby([\"drv\", \"tyre\"])[\"delta_best\"].mean().reset_index()\n",
    "    ).rename(columns={\"delta_best\": \"avg_delta_best_driver_tyre\"})\n",
    "    df = df.merge(avg_driver_tyre, on=[\"drv\", \"tyre\"], how=\"left\")\n",
    "\n",
    "    if \"best_s_lap\" in df.columns:\n",
    "        df[\"is_stint_fastest_lap\"] = (\n",
    "            df[\"lap_time\"] == df[\"best_s_lap\"]\n",
    "        ).astype(int)\n",
    "    else:\n",
    "        df[\"is_stint_fastest_lap\"] = np.nan\n",
    "\n",
    "    def _track(row):\n",
    "        if pd.isna(row[\"track_temp\"]):\n",
    "            return \"WET_OR_INTERMEDIATE\" if row[\"tyre\"] in [\"INTERMEDIATE\", \"WET\"] else \"UNKNOWN_TEMP\"\n",
    "        if row[\"tyre\"] in [\"INTERMEDIATE\", \"WET\"]:\n",
    "            return \"WET_OR_INTERMEDIATE\"\n",
    "        if row[\"track_temp\"] > 25:\n",
    "            return \"DRY_HOT\"\n",
    "        if row[\"track_temp\"] < 15:\n",
    "            return \"DRY_COLD\"\n",
    "        return \"DRY_NORMAL\"\n",
    "\n",
    "    df[\"track_condition\"] = df.apply(_track, axis=1)\n",
    "    logger.info(\"Features adicionadas. Shape: %s\", df.shape)\n",
    "    return df\n",
    "\n",
    "def load_multi_year_data(\n",
    "    *,\n",
    "    years: List[int],\n",
    "    events: List[str],\n",
    "    driver_filter: Optional[str] = None,\n",
    "    CACHE_DIR: str = CACHE_DIR,\n",
    ") -> pd.DataFrame:\n",
    "    all_main, all_delta = [], []\n",
    "    for yr in years:\n",
    "        for ev in events:\n",
    "            main_df = generate_main_dataset(\n",
    "                year=yr,\n",
    "                event=ev,\n",
    "                CACHE_DIR=CACHE_DIR,\n",
    "                driver_filter=driver_filter,\n",
    "                years_filter=years,\n",
    "            )\n",
    "            delta_df = generate_deltas_dataset(\n",
    "                year=yr,\n",
    "                event=ev,\n",
    "                CACHE_DIR=CACHE_DIR,\n",
    "                driver_filter=driver_filter,\n",
    "                years_filter=years,\n",
    "            )\n",
    "            if not main_df.empty:\n",
    "                all_main.append(main_df)\n",
    "            if not delta_df.empty:\n",
    "                all_delta.append(delta_df)\n",
    "\n",
    "    main_all = pd.concat(all_main, ignore_index=True) if all_main else pd.DataFrame()\n",
    "    delta_all = pd.concat(all_delta, ignore_index=True) if all_delta else pd.DataFrame()\n",
    "\n",
    "    combined = merge_fastf1_dataframes(main_all, delta_all)\n",
    "    if combined.empty:\n",
    "        logger.error(\"Nenhum dado disponível após merge\")\n",
    "        return combined\n",
    "\n",
    "    return add_analysis_features(combined)\n",
    "    \n",
    "def fill_outliers_with_median(df, col, n_std=2.5):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    df_copy['group_mean'] = df_copy.groupby(['drv', 'tyre'])[col].transform('mean')\n",
    "    df_copy['group_std'] = df_copy.groupby(['drv', 'tyre'])[col].transform('std')\n",
    "    \n",
    "    df_copy['group_median'] = df_copy.groupby(['drv', 'tyre'])[col].transform('median')\n",
    "\n",
    "    outlier_condition = (df_copy[col] > df_copy['group_mean'] + n_std * df_copy['group_std'])\n",
    "    \n",
    "    num_outliers_before = outlier_condition.sum()\n",
    "    logger.info(f\"Número de outliers identificados em '{col}': {num_outliers_before}\")\n",
    "\n",
    "    df_copy.loc[outlier_condition, col] = df_copy.loc[outlier_condition, 'group_median']\n",
    "    \n",
    "    df_filled = df_copy.drop(columns=['group_mean', 'group_std', 'group_median'])\n",
    "\n",
    "    return df_filled\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    YEARS = [2023]  \n",
    "    EVENTS = [\"British Grand Prix\"]  \n",
    "    DRIVER = None  \n",
    "\n",
    "    df_final = load_multi_year_data(\n",
    "        years=YEARS,\n",
    "        events=EVENTS,\n",
    "        driver_filter=DRIVER,\n",
    "    )\n",
    "    \n",
    "    df_final = fill_outliers_with_median(df_final, 'lap_time', n_std=2.5)\n",
    "\n",
    "    if not df_final.empty:\n",
    "        driver_tag = DRIVER or \"ALL\"\n",
    "        fname = f\"analyzed_fastf1_data_{driver_tag}_{'_'.join(map(str, YEARS))}\"\n",
    "        logger.info(\"Dataframe salvo como '%s' (%d linhas).\", fname, len(df_final))\n",
    "    else:\n",
    "        logger.warning(\"Pipeline terminou sem dados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0518fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "def save_data_to_sql(df, table_name, db_type, db_details, if_exists='replace', index=False):\n",
    "    conn_str = \"\"\n",
    "    try:\n",
    "        if db_type == 'sqlite':\n",
    "            conn_str = f\"sqlite:///{db_details['database']}\"\n",
    "        elif db_type == 'mysql':\n",
    "            conn_str = (\n",
    "                f\"mysql+mysqlconnector://{db_details['user']}:{db_details['password']}\"\n",
    "                f\"@{db_details['host']}/{db_details['database']}\"\n",
    "            )\n",
    "        elif db_type == 'postgresql':\n",
    "            conn_str = (\n",
    "                f\"postgresql+psycopg2://{db_details['user']}:{db_details['password']}\"\n",
    "                f\"@{db_details['host']}:{db_details.get('port', 5432)}/{db_details['database']}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Erro: Tipo de banco de dados '{db_type}' não suportado\")\n",
    "            return False\n",
    "\n",
    "        engine = create_engine(conn_str)\n",
    "        df.to_sql(name=table_name, con=engine, if_exists=if_exists, index=index)\n",
    "        print(f\"Dados salvos com sucesso na tabela '{table_name}' no banco de dados {db_type}\")\n",
    "        return True\n",
    "    except ImportError as e:\n",
    "        print(f\"Erro: O driver para o banco de dados '{db_type}' não está instalado. Detalhes: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar dados no banco de dados {db_type}: {e}\")\n",
    "        return False\n",
    "\n",
    "postgresql_db_details = {\n",
    "    'user': os.environ.get('PG_USER'),        \n",
    "    'password': os.environ.get('PG_PASSWORD'),\n",
    "    'host': os.environ.get('PG_HOST'),\n",
    "    'port': int(os.environ.get('PG_PORT')),\n",
    "    'database': os.environ.get('PG_DATABASE')\n",
    "}\n",
    "\n",
    "table_name = 'fastf1_analysis_data'\n",
    "\n",
    "print(f\"1. Carregando dados do DF:\")\n",
    "df_fastf1 = df_final.copy() if df_final is not None else pd.DataFrame()\n",
    "\n",
    "if df_fastf1 is not None and not df_fastf1.empty:\n",
    "    print(f\"\\n2. Tentando salvar o DataFrame na tabela '{table_name}' no PostgreSQL...\")\n",
    "    success = save_data_to_sql(df_fastf1, table_name, 'postgresql', postgresql_db_details, if_exists='replace')\n",
    "\n",
    "    if success:\n",
    "        print(\"\\nDados salvos com sucesso no PostgreSQL.\")\n",
    "    else:\n",
    "        print(\"\\nNão foi possível salvar os dados no PostgreSQL.\")\n",
    "else:\n",
    "    print(\"\\nO DataFrame não pôde ser carregado ou está vazio. Não é possível prosseguir para salvar no PostgreSQL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aac030",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVER_TO_ANALYZE = 'HAM'\n",
    "\n",
    "if df_final is not None and not df_final.empty:\n",
    "    try:\n",
    "        df_visual = df_final.copy()\n",
    "        driver_df_visual = df_visual[df_visual['drv'] == DRIVER_TO_ANALYZE].copy()\n",
    "\n",
    "        if driver_df_visual.empty:\n",
    "            print(f\"Nenhum dado encontrado para o piloto '{DRIVER_TO_ANALYZE}' para visualização\")\n",
    "            print(f\"Pilotos disponíveis no dataset: {df_visual['drv'].unique().tolist()}\")\n",
    "        else:\n",
    "            print(f\"Dados filtrados para visualização do piloto: {DRIVER_TO_ANALYZE}. Total de {len(driver_df_visual)} voltas\")\n",
    "            driver_df_visual['stint_group_id'] = (driver_df_visual['s_lap'] == 1).cumsum()\n",
    "\n",
    "            compound_colors = {\n",
    "                'SOFT': '#FF3333',\n",
    "                'MEDIUM': '#FFCC00',\n",
    "                'HARD': '#CCCCCC',\n",
    "                'INTERMEDIATE': '#009900',\n",
    "                'WET': '#0000FF',\n",
    "                'UNKNOWN': '#800080',\n",
    "                'TEST_UNKNOWN': '#808000'\n",
    "            }\n",
    "\n",
    "            for year in sorted(driver_df_visual['year'].unique()):\n",
    "                df_year = driver_df_visual[driver_df_visual['year'] == year]\n",
    "\n",
    "                print(f\"\\n Ano: {year} | Voltas: {len(df_year)}\")\n",
    "\n",
    "                # 1. Tempo de volta por stint\n",
    "                plt.figure(figsize=(12, 7))\n",
    "                for (stint_group_id, tyre), group in df_year.groupby(['stint_group_id', 'tyre']):\n",
    "                    color = compound_colors.get(tyre, '#000000')\n",
    "                    plt.plot(group['s_lap'], group['lap_time'], marker='o', linestyle='-', color=color,\n",
    "                             label=f'Stint {stint_group_id} ({tyre})')\n",
    "                plt.title(f'Tempo de Volta por Stint - {DRIVER_TO_ANALYZE} - {year}')\n",
    "                plt.xlabel('Volta do Stint')\n",
    "                plt.ylabel('Tempo de Volta (s)')\n",
    "                plt.grid(True, linestyle='--', alpha=0.7)\n",
    "                plt.legend(title='Stint/Pneu', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                # 2. Degradação (delta_best)\n",
    "                plt.figure(figsize=(12, 7))\n",
    "                for (stint_group_id, tyre), group in df_year.groupby(['stint_group_id', 'tyre']):\n",
    "                    color = compound_colors.get(tyre, '#000000')\n",
    "                    plt.plot(group['s_lap'], group['delta_best'], marker='o', linestyle='-', color=color,\n",
    "                             label=f'Stint {stint_group_id} ({tyre})')\n",
    "                plt.title(f'Degradação do Pneu (Δ para melhor volta) - {DRIVER_TO_ANALYZE} - {year}')\n",
    "                plt.xlabel('Volta do Stint')\n",
    "                plt.ylabel('Delta para Melhor Volta (s)')\n",
    "                plt.grid(True, linestyle='--', alpha=0.7)\n",
    "                plt.legend(title='Stint/Pneu', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                # 3. Tempo médio por stint\n",
    "                plt.figure(figsize=(12, 7))\n",
    "                stint_avg = df_year.groupby(['stint_group_id', 'tyre'])['lap_time'].mean().reset_index()\n",
    "                stint_avg['label'] = stint_avg.apply(lambda row: f'Stint {row.stint_group_id} ({row.tyre})', axis=1)\n",
    "                plt.bar(stint_avg['label'], stint_avg['lap_time'],\n",
    "                        color=[compound_colors.get(c, '#000000') for c in stint_avg['tyre']])\n",
    "                plt.title(f'Tempo Médio por Stint - {DRIVER_TO_ANALYZE} - {year}')\n",
    "                plt.xlabel('Stint')\n",
    "                plt.ylabel('Tempo Médio de Volta (s)')\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                # 4. Volta vs combustível\n",
    "                plt.figure(figsize=(12, 7))\n",
    "                for tyre, group in df_year.groupby('tyre'):\n",
    "                    color = compound_colors.get(tyre, '#000000')\n",
    "                    plt.scatter(group['fuel_kg'], group['lap_time'], alpha=0.6, label=tyre, color=color)\n",
    "                plt.title(f'Tempo de Volta vs Combustível - {DRIVER_TO_ANALYZE} - {year}')\n",
    "                plt.xlabel('Peso Estimado de Combustível (kg)')\n",
    "                plt.ylabel('Tempo de Volta (s)')\n",
    "                plt.grid(True, linestyle='--', alpha=0.7)\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                # 5. Volta vs % do stint\n",
    "                plt.figure(figsize=(12, 7))\n",
    "                for tyre, group in df_year.groupby('tyre'):\n",
    "                    color = compound_colors.get(tyre, '#000000')\n",
    "                    plt.scatter(group['s_pct'] * 100, group['lap_time'], alpha=0.6, label=tyre, color=color)\n",
    "                plt.title(f'Tempo de Volta vs % do Stint - {DRIVER_TO_ANALYZE} - {year}')\n",
    "                plt.xlabel('% do Stint')\n",
    "                plt.ylabel('Tempo de Volta (s)')\n",
    "                plt.grid(True, linestyle='--', alpha=0.7)\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            print(\"\\nVisualização de análise de desgaste por ano concluída.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar ou visualizar o arquivo CSV: {e}\")\n",
    "else:\n",
    "    logger.error(f\"Não foi possível carregar o DataFrame para visualização. Verifique se o DataFrame está vazio ou se ocorreu um erro anterior.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
